# GrowingSparseSNN üß†üå±

**Digital Organism with Dynamic Growing Spiking Neural Networks**

A research project exploring **neurogenesis** (neuron growth), **synaptic pruning**, and **continual learning** in Spiking Neural Networks (SNNs), optimized for AMD GPUs with ROCm.

## üéØ Core Concepts

- **Dynamic Growth**: Neurons and connections emerge as the organism learns new patterns
- **Energy Efficiency**: Natural sparsity of SNNs + aggressive pruning + controlled growth
- **Continual Learning**: Learn without catastrophic forgetting
- **Hardware-Aware**: Optimized for AMD GPU (Gigabyte AI PRO R9700) using PyTorch + ROCm

## üß™ Hypothesis

> A SNN with dynamically growing hidden layers (neurogenesis controlled by novelty/saturation metrics) + pruning based on low firing rates + learning via STDP or surrogate gradients, can learn exploration/foraging tasks with less energy and better adaptation than a fixed-size network of the same maximum capacity.

## üèóÔ∏è Architecture

### GrowingSparseSNN Features

- **Input**: Environment observation (e.g., 15√ó15 grid √ó 2 channels ‚Üí ~450 features)
- **Dynamic Hidden Layer**: Starts small (64 LIF neurons), grows up to max (512-1024)
- **Output**: 4 actions (up, down, left, right) - rate-based or temporal coding
- **Plasticity Mechanisms**:
  - **Growth (Neurogenesis)**: Add neurons when avg firing rate < threshold (0.05 spikes/timestep)
  - **Pruning**: Remove neurons with firing rate < 0.005 after evaluation window
  - **Synaptic Learning**: Surrogate gradient + REINFORCE or simple STDP

## üì¶ Installation

### Prerequisites
- Docker + ROCm support (for GPU training, optional)
- AMD GPU with ROCm drivers (optional, can run on CPU)
- Python 3.10+
- [UV](https://github.com/astral-sh/uv) - Fast Python package manager

### Quick Start

#### Local Setup with UV
```bash
# Clone the repository
git clone https://github.com/nfriacowboy/growingSparseSNN.git
cd growingSparseSNN

# Install UV
curl -LsSf https://astral.sh/uv/install.sh | sh

# Setup environment (creates venv + installs deps)
./setup.sh

# Activate virtual environment
source .venv/bin/activate

# Run tests
pytest tests/ -v

# Train model
python src/training/train.py
```

#### Using Docker + ROCm (alternative for GPU)
```bash
# Build Docker image with ROCm
docker build -t growing-snn:rocm -f docker/Dockerfile.rocm .

# Run container with GPU access
docker run --rm -it --device=/dev/kfd --device=/dev/dri \
  --group-add video --ipc=host --cap-add=SYS_PTRACE \
  --security-opt seccomp=unconfined \
  -v $(pwd):/workspace growing-snn:rocm

# Inside container - run basic test
python tests/test_growth.py
```

## üöÄ Usage

### Basic Training

```python
from src.models.growing_snn import GrowingSparseSNN
from src.environments.grid_world import ForagingGrid

# Create organism
organism = GrowingSparseSNN(
    input_features=450, 
    init_hidden=64, 
    max_hidden=512
)

# Create environment
env = ForagingGrid(size=15, n_food=10)

# Train (with growth and pruning)
trainer = AdaptiveTrainer(organism, env)
trainer.train(episodes=1000, grow_interval=100, prune_interval=50)
```

## üìä Monitoring

The project uses Prometheus + Grafana for real-time monitoring:

- Neuron count over time
- Firing rates and sparsity
- Energy consumption estimates
- Learning curves
- Growth/pruning events

Access dashboard at `http://localhost:3000` after starting services.

## üß¨ Project Structure

```
growingSparseSNN/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ growing_snn.py      # Main GrowingSparseSNN class
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lif_neuron.py       # LIF neuron implementations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ plasticity.py       # Growth/pruning/STDP rules
‚îÇ   ‚îú‚îÄ‚îÄ environments/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ grid_world.py       # Foraging grid environment
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base_env.py         # Base environment interface
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py          # Training loop with growth
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄrl_agent.py         # RL integration
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/
‚îÇ       ‚îú‚îÄ‚îÄ metrics.py          # OpenMetrics exporter
‚îÇ       ‚îî‚îÄ‚îÄ prometheus.py       # Prometheus client
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_growth.py          # Growth mechanism tests
‚îÇ   ‚îú‚îÄ‚îÄ test_pruning.py         # Pruning tests
‚îÇ   ‚îî‚îÄ‚îÄ test_learning.py        # Learning tests
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.rocm         # ROCm-enabled container
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml      # Services orchestration
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îú‚îÄ‚îÄ model_config.yaml       # Model hyperparameters
‚îÇ   ‚îî‚îÄ‚îÄ training_config.yaml    # Training settings
‚îú‚îÄ‚îÄ experiments/
‚îÇ   ‚îî‚îÄ‚îÄ notebooks/              # Jupyter notebooks for analysis
‚îî‚îÄ‚îÄ docs/
    ‚îî‚îÄ‚îÄ architecture.md         # Detailed architecture docs
```

## üìà Experiments

- Baseline: Fixed-size SNN (512 neurons)
- Growing: Dynamic growth from 64‚Üí512 neurons
- Growing+Pruning: Growth + aggressive pruning
- Metrics: Energy efficiency, sample efficiency, final performance

## üî¨ Based on Recent Research

- Structural plasticity in sparse SNNs (arXiv 2024/2025)
- Dynamic pruning + synaptic regeneration
- LIF neurons + STDP/R-STDP
- ROCm optimization patterns for SNN

## üìù License

MIT License - See LICENSE file

## ü§ù Contributing

Contributions welcome! Please open an issue first to discuss proposed changes.

## üìß Contact

- GitHub: [@nfriacowboy](https://github.com/nfriacowboy)
- Project: [growingSparseSNN](https://github.com/nfriacowboy/growingSparseSNN)

---

**Status**: üöß Active Development | **GPU**: AMD Radeon R9700 + ROCm | **Framework**: PyTorch + Norse
